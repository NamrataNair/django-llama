# Generated by Django 4.2.7 on 2023-11-17 14:55

from django.db import migrations, models


class Migration(migrations.Migration):
    initial = True

    dependencies = []

    operations = [
        migrations.CreateModel(
            name="InferenceParamsPreset",
            fields=[
                (
                    "id",
                    models.BigAutoField(
                        auto_created=True,
                        primary_key=True,
                        serialize=False,
                        verbose_name="ID",
                    ),
                ),
                (
                    "name",
                    models.CharField(
                        help_text="Name of the preset",
                        max_length=128,
                        verbose_name="Name",
                    ),
                ),
                (
                    "max_tokens",
                    models.IntegerField(
                        default=-1,
                        help_text="The maximum number of tokens to generate. If max_tokens <= 0, the maximum number of tokens to generate is unlimited and depends on the model's context window size (default).",
                    ),
                ),
                (
                    "temperature",
                    models.FloatField(
                        default=0.2, help_text="The temperature to use for sampling."
                    ),
                ),
                (
                    "top_p",
                    models.FloatField(
                        default=0.95, help_text="The top-p value to use for sampling."
                    ),
                ),
                (
                    "top_k",
                    models.PositiveIntegerField(
                        default=40, help_text="The top-k value to use for sampling."
                    ),
                ),
                (
                    "tfs",
                    models.FloatField(
                        default=1.0,
                        help_text="Tail free sampling: 1.0 (default) disables it",
                    ),
                ),
                (
                    "stop",
                    models.JSONField(
                        blank=True,
                        help_text="A list of strings to stop generation when encountered.",
                        null=True,
                    ),
                ),
                (
                    "repeat_penalty",
                    models.FloatField(
                        default=1.0,
                        help_text="The penalty to apply to repeated tokens: default: 1.",
                    ),
                ),
                (
                    "presence_penalty",
                    models.FloatField(
                        default=0.0,
                        help_text="The presence penalty: 0 (default) disables it",
                    ),
                ),
                (
                    "frequency_penalty",
                    models.FloatField(
                        default=0.0,
                        help_text="The frequency penalty: 0 (default) disables it",
                    ),
                ),
            ],
        ),
    ]
